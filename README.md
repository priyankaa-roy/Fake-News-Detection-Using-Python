# ğŸ“° Detecting Fake News ğŸ”âœ¨
This repository contains a Python-based solution to detect fake news using a dataset from Kaggle. Leveraging natural language processing (NLP) techniques and machine learning algorithms, the project identifies fake news articles with high accuracy. ğŸš€ğŸ“ˆ

## ğŸŒŸProject Overview
Fake news has become a widespread issue in the digital age, impacting public opinion and decision-making. ğŸ—£ï¸ğŸ–¥ï¸This project aims to classify news articles as real or fake by training a predictive model on labeled datasets. The pipeline includes:
- ğŸ§¹ Data preprocessing
- ğŸ” Feature extraction
- ğŸ¤– Model training
- ğŸ“Š Model evaluation

## Features
âœ”ï¸ Data cleaning and preprocessing (handling missing values, text normalization)

âœ”ï¸ Feature extraction using `TF-IDF vectorization`

âœ”ï¸ Machine learning classification (e.g., Logistic Regression, Naive Bayes)

âœ”ï¸ Model evaluation (accuracy, precision, recall, and F1 score)

âœ”ï¸ Python notebook for reproducibility

## ğŸ“Dataset
The dataset used for this project is sourced from Kaggle and contains labeled news articles categorized as real or fake.

ğŸ’¾Dataset: Use Kaggle to download Fake News Dataset

## âš™ï¸Installation

1. Clone the repository:

git clone [https://github.com/your-username/fake-news-detection.git](https://github.com/priyankaa-roy/Fake-News-Detection-Using-Python)
cd fake-news-detection

2. Set up a virtual environment:

python -m venv env
source env/bin/activate      # On Windows: env\Scripts\activate

3. Install required dependencies:

pip install -r requirements.txt

5. Download the Kaggle dataset and place it in the data folder.


## ğŸ”¬Methodology

### ğŸ§¹Data Preprocessing:
- Removing null values and duplicates
- Text cleaning: lowercasing, removing punctuation, and stopword removal

### âœï¸Feature Extraction:
- Using TF-IDF vectorization to convert text data into numerical form for modeling

### ğŸ¤–Model Training:
- Training classifiers such as Logistic Regression, Naive Bayes, or Support Vector Machines

### ğŸ“ŠModel Evaluation:
- Evaluating the model's performance using metrics like accuracy, precision, recall, and F1 score
  

## ğŸ¯Results
Metric	Value

Accuracy	93%

Precision	93%

Recall	94%

F1 Score	93%

![image](https://github.com/user-attachments/assets/bdaa7c03-9ed2-44e0-a887-f976841cd6d3)




## ğŸ’»Technologies Used
- `Programming Language`: Python ğŸ
- `Libraries`: Pandas ğŸ¼, NumPy ğŸ”¢, Scikit-learn ğŸ¤–, NLTK ğŸ—£ï¸, Matplotlib ğŸ“Š, Seaborn ğŸ¨
- `Modeling Techniques`: Logistic Regression, Naive Bayes, TF-IDF
- `Visualization`: Matplotlib, Seaborn

## ğŸ¤Contributing
Contributions are welcome! Feel free to open issues or submit pull requests to improve this project.
### ğŸ“Œ Steps to Contribute:
1. Fork the repository
2. Create a new branch:
- git checkout -b feature-branch-name
3. Commit your changes:
- git commit -m "Add feature"
4. Push to the branch:
- git push origin feature-branch-name
5. Open a pull request

## ğŸ“œLicense
This project is licensed under the MIT License. ğŸ“See the LICENSE file for details.
